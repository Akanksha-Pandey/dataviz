```{r echo = FALSE, message = FALSE}
# run setup script
source("_common.R")
```


# Visualizing distributions: Empirical cumulative density functions and q-q plots

In Chapter \@ref(histograms-density-plots), I described how we can visualize distributions with histograms or density plots. Both of these approaches are highly intuitive and visually appealing. However, as discussed in that chapter, they both share the limitation that the resulting figure depends to a substantial degree on parameters the user has to choose, such as the bin width for histograms and the bandwidth for density plots. As a result, both have to be considered as an interpretation of the data rather than a direct visualization of the data itself.

As an alternative to using histograms or density plots, we could simply show all the data points individually, as a point cloud (see e.g. Chapter \@ref(boxplots-violins)). However, this approach becomes unwieldy for very large datasets, and in any case there is value in aggregate methods that highlight properties of the distribution rather than the individual data points. To solve this problem, statisticians have invented empirical cumulative density functions (ecdfs) and quantile--quantile (q-q) plots. These types of visualizations require no arbitrary parameter choices, and they show all of the data at once. Unfortunately, they are a little less intuitive than a histogram or a density plot is, and I don't see them used frequently outside of highly technical publications. They are quite popular among statisticians, though, and I think anybody interested in data visualization should be familiar with these techniques.


## Empirical cumulative density functions

To illustrate cumulative empirical density functions, I will begin with a hypothetical example that is closely modeled after something I deal with a lot as a professor in the classroom: a dataset of student grades. Assume our hypothetical class has 50 students, and the students just completed an exam on which they could score between 0 and 100 points. How can we best visualize the class performance, for example to determine appropriate grade boundaries?

We can plot the total number of students that have received at least a certain number of points versus all possible point scores. This plot will be an ascending function, starting at 0 for 0 points and ending at 50 for 100 points. A different way of thinking about this visualization is the following: We can rank all students by the number of points they obtained, in ascending order (so the student with the fewest points receives the lowest rank and the student with the most points the highest), and then plot the rank versus the actual points obtained. The result is an *empirical cumulative distribution function* (ecdf) or simply *cumulative distribution.* Each dot represents one student, and the lines visualize the highest student rank observed for any possible point value.

```{r student-grades}
set.seed(4211)
points = round(c(rnorm(47, mean = 82, sd = 10), 45, 51, 67))
points[points > 100] <- 100
student_data <- data.frame(points, rank = rank(points, ties.method = "random"))
ggplot(student_data, aes(x = points, y = 50*..y..)) + 
  stat_ecdf(geom = "step", color = "#0072B2") +
  geom_point(aes(y = rank), color = "#0072B2") +
  scale_x_continuous(limits = c(40, 102), expand = c(0, 0), breaks = 10*(4:10)) +
  scale_y_continuous(limits = c(-.5, 55), expand = c(0, 0), name = "student rank (ascending)") +
  theme_dviz_grid() +
  theme(axis.line.x = element_blank())
```


You may wonder what happens if we rank the students the other way round, in descending order. This ranking simply flips the function on its head. The result is still an empirical cumulative distribution function, but the lines now represent the lowest student rank observed for any possible point value. 

```{r student-grades-desc}
ggplot(student_data, aes(x = points, y = 51-50*..y..)) + 
  stat_ecdf(geom = "step", color = "#0072B2") +
  geom_point(aes(y = 51-rank), color = "#0072B2") +
  scale_x_continuous(limits = c(40, 102), expand = c(0, 0), breaks = 10*(4:10)) +
  scale_y_continuous(limits = c(-.5, 55), expand = c(0, 0), name = "student rank (descending)") +
  theme_dviz_grid() +
  theme(axis.line.x = element_blank())

```

Ascending cumulative distribution functions are more widely known and more commonly used than descending ones, but both have important applications. Descending cumulative distribution functions are critical when we want to visualize highly skewed distributions (see below).

In practical applications, it is quite common to draw the ecdf without highlighting the individual points and to normalize the ranks by the maximum rank, so that the *y* axis represents the cumulative frequency. For the student grades example, these modifications yield the following plot.


```{r student-grades-normalized}
ggplot(student_data, aes(x = points, y = ..y..)) + 
  stat_ecdf(geom = "step", color = "#0072B2") +
  scale_x_continuous(limits = c(40, 102), expand = c(0, 0), breaks = 10*(4:10)) +
  scale_y_continuous(limits = c(-.01, 1.01), expand = c(0, 0), name = "cumulative frequency") +
  theme_dviz_grid() +
  theme(axis.line.x = element_blank())
```

We can directly read off key properties of the student grade distribution from this plot. For example, a quarter of the students (25%) received less than 75 points. The median point value (corresponding to a cumulative frequency of 0.5) is 81. Approximately 20% of the students received 90 points or more.

I find ecdfs handy for assigning grade boundaries because they help me locate the exact cutoffs that minimize student unhappiness. For example, in this example, there's a fairly long horizontal line right below 80 points, followed by a steep rise right at 80. This feature is caused by three students receiving 80 points on their exam while the next poorer performing student received only 76. In this scenario, I might decide that everybody with a point score of 80 or more receives a B and everybody with 79 or less receives a C. The three students with 80 points are happy that they just made a B, and the student with 76 realizes that they would have had to perform much better to not receive a C. If I had set the cutoff at 77, the distribution of letter grades would have been exactly the same, but I might find the student with 76 points visiting my office hoping to negotiate their grade up. Likewise, if I had set the cutoff at 81, I would likely have had three students in my office trying to negotiate their grade.

## Highly skewed distributions

Many empirical datasets display highly skewed distributions, in particular right-skewed, and these distributions can be challenging to visualize. Examples include the number of people living in different cities or counties, the number of interaction partners of individual proteins in protein--protein interaction networks, the frequency with which individual words appear in a book, the number of academic papers written by different authors, the net worth of individuals, and the number of contacts in a social network (@Clauset-et-al-2009).

As an example, I will here discuss the number of people living in different US counties according to the 2010 US Census. This distribution has a very long tail to the right. Even though most counties have relatively small numbers of inhabitants (the median is 25,857), a few counties have extremely large numbers of inhabitants (e.g., Los Angeles County, with 9,818,605 inhabitants). If we try to visualize the distribution of population counts as either a density plot or an ecdf, we obtain figures that are essentially useles.

```{r county-populations, message=FALSE, warning=FALSE, fig.width = 8.5, fig.asp = 0.309}
library(openintro)

p1 <- ggplot(countyComplete, aes(x=pop2010)) + 
  geom_density(fill = "#56B4E9", color = "transparent") +
  scale_x_continuous(expand = c(0.01, 0), name = "number of inhabitants",
                     breaks = c(0, 2.5e6, 5e6, 7.5e6),
                     labels = c(expression(0), expression(2.5 %*% 10^6),
                                expression(5 %*% 10^6), expression(7.5 %*% 10^6))) +
  scale_y_continuous(expand = c(0, 0), name = expression(paste("density [x", 10^-5, "]")),
                     breaks = c(0, 4e-6, 8e-6, 1.2e-5),
                     labels = c(0, 0.4, 0.8, 1.2)) +
  theme_dviz_grid(12)

p2 <- ggplot(countyComplete, aes(x=pop2010)) + 
  stat_ecdf(geom = "step", color = "#0072B2", pad = FALSE) +
  scale_x_continuous(expand = c(0.01, 0), name = "number of inhabitants",
                     breaks = c(0, 2.5e6, 5e6, 7.5e6),
                     labels = c(expression(0), expression(2.5 %*% 10^6),
                                expression(5 %*% 10^6), expression(7.5 %*% 10^6))) +
  scale_y_continuous(expand = c(0.01, 0), name = "cumulative frequency") +
  theme_dviz_grid(12)

plot_grid(p1, p2, labels = 'auto')
```

The density plot (part a) shows a sharp peak right at 0, and virtually no details of the distribution are visible. Similarly, the ecdf (part b) shows a rapid rise near 0, and again no details of the distribution are visible. For this particular dataset, one solution could be to log-transform the data, and to visualize the distribution of the log-transformed values. This transformation works here because the population numbers in counties follow a nearly perfect log-normal distribution (see below). Indeed, the density plot of the log-transformed values shows a nice bell curve, and the corresponding ecdf shows a nice sigmoidal.

```{r county-populations-log, message=FALSE, warning=FALSE, fig.width = 8.5, fig.asp = 0.309}
p1_log <- ggplot(countyComplete, aes(x=log10(pop2010))) + 
  geom_density(fill = "#56B4E9", color = "transparent") +
  scale_x_continuous(expand = c(0.01, 0), name = "log10(number of inhabitants)") +
  scale_y_continuous(expand = c(0, 0), name = "density") +
  theme_dviz_grid(12)

p2_log <- ggplot(countyComplete, aes(x=log10(pop2010))) + 
  stat_ecdf(geom = "step", color = "#0072B2", pad = FALSE) +
  scale_x_continuous(expand = c(0.01, 0), name = "log10(number of inhabitants)") +
  scale_y_continuous(expand = c(0.01, 0), name = "cumulative frequency") +
  theme_dviz_grid(12)

plot_grid(p1_log, p2_log, labels = 'auto')
```

Alternatively, we can plot a descending ecdf with logarithmic *x* and *y* axes. This visualization helps us understand exactly how the right tail decays. *need a few sentences about power laws here.*

```{r county-populations-tail-log-log, message=FALSE, warning=FALSE}
ggplot(countyComplete, aes(x=pop2010, y = 1-..y..)) + 
  stat_ecdf(geom = "step", color = "#0072B2", pad = FALSE) +
  scale_x_log10(expand = c(0.01, 0),
                breaks = c(1e2, 1e3, 1e4, 1e5, 1e6, 1e7),
                labels = c(expression(10^2), expression(10^3), expression(10^4),
                           expression(10^5), expression(10^6), expression(10^7)),
                name = "number of county inhabitants") +
  scale_y_log10(expand = c(0.01, 0), breaks = c(1e-3, 1e-2, 1e-1, 1), name = "relative frequency") +
  theme_dviz_grid()
```

The number of times words are used in a book tend to follow a perfect power law. The next example uses the frequencies of words in the novel Moby Dick. When plotted as descending ecdf on a log-log plot, we see a nearly perfect straight line, indicating a true power-law distribution of word frequencies.

```{r word-counts-tail-log-log, message=FALSE, warning=FALSE}
wc <- read.csv("datasets/Moby_Dick_word_counts.csv")
ggplot(wc, aes(x=count, y = 1-..y..)) + 
  stat_ecdf(geom = "step", color = "#0072B2", pad = FALSE) +
  scale_x_log10(expand = c(0.01, 0), breaks = c(1, 10, 100, 1000, 10000),
                name = "number of times word is used") +
  scale_y_log10(expand = c(0.01, 0), breaks = c(1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1),
                labels = c(expression(10^-5), expression(10^-4), expression(10^-3),
                           expression(10^-2), expression(10^-1), expression(10^0)),
                name = "fraction of words") +
  theme_dviz_grid()
```

## Quantile--quantile plots


```{r student-grades-qq}
# estimate distribution parameters (mean and sd)
params <- as.list(MASS::fitdistr(student_data$points, "normal")$estimate)
ggplot(student_data, aes(sample = points)) + 
  geom_abline(slope = 1, intercept = 0, color = "grey70") +
  stat_qq(dparams = params, color = "#0072B2") +
  scale_x_continuous(breaks = 10*(5:10)) +
  scale_y_continuous(name = "observed", breaks = 10*(5:10)) +
  theme_dviz()
```

```{r county-populations-qq}
# estimate distribution parameters (mean and sd)
params <- as.list(MASS::fitdistr(log(countyComplete$pop2010), "normal")$estimate)
ggplot(countyComplete, aes(sample = log(pop2010))) + 
  geom_abline(slope = 1, intercept = 0, color = "grey70") +
  stat_qq(dparams = params, color = "#0072B2") +
  scale_x_continuous(breaks = 5+2.5*(0:4)) +
  scale_y_continuous(name = "observed", breaks = 5+2.5*(0:4)) +
  theme_dviz()
```

The agreement between the observed and the theoretical values is exceptional. This demonstrates that the distribution of population counts among counties is indeed log-normal, as I suggested earlier in this chapter. *Give brief explanation for why. Random, multiplicative growth.*
