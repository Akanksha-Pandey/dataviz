```{r echo = FALSE, message = FALSE, warning = FALSE}
# run setup script
source("_common.R")

library(forcats)
library(patchwork)
library(lubridate)
library(mgcv)
library(mvtnorm)
library(rlang)
library(tidyr)
```

# Visualizing uncertainty {#visualizing-uncertainty}

*Chapter under construction. Tentative outline:*

- *Error bars and confidence bands*
- *Distributions*
- *Hypothetical outcomes plots*
- *Value suppression*


## Error bars and confidence bands

```{r fig.asp = 1.2}
n <- c(10, 30, 100, 300, 1000)

df <- data.frame(n = unlist(lapply(n, function(x) rep(x, x))),
                 x = c(rnorm(sum(n))))

df %>% group_by(n) %>%
  summarize(mean = mean(x),
            se = sd(x)/sqrt(n())) -> df_mean

p1 <- ggplot(df, aes(x = factor(n), y = x)) + 
  geom_point(size = 0.5, position = position_jitter(width = 0.3)) +
  scale_x_discrete(breaks = NULL, name = NULL) +
  scale_y_continuous(breaks = c(-2, 0, 2)) +
  theme_dviz_hgrid() +
  theme(plot.margin = margin(3, 0, 14, 0))
p2 <- ggplot(df, aes(x = factor(n), y = x)) + 
  geom_boxplot(fill = "gray90") +
  scale_x_discrete(breaks = NULL, name = NULL) +
  scale_y_continuous(breaks = c(-2, 0, 2)) +
  theme_dviz_hgrid() +
  theme(plot.margin = margin(3, 0, 14, 0))
p3 <- ggplot(df_mean, aes(x = factor(n), y = mean)) + 
  geom_pointrange(aes(ymin = mean - se, ymax = mean + se)) +
  scale_x_discrete(name = "n") +
  scale_y_continuous(breaks = c(-.2, 0, .2), name = "mean(x)") +
  theme_dviz_hgrid()

p1 + p2 + p3 + plot_layout(ncol = 1)

```


```{r fig.width = 5}
cows %>% filter(breed != "Canadian") %>%
  group_by(breed) %>%
  summarize(mean = mean(butterfat),
            se = sd(butterfat)/sqrt(n())) %>%
  mutate(breed = fct_reorder(breed, desc(mean)))-> cow_means

ggplot(cow_means, aes(x = breed, y = mean, ymin = mean - se, ymax = mean + se)) +
  geom_pointrange() +
  scale_x_discrete(labels = c("Jersey", "Guernsey", "Ayrshire", "Holstein-\nFriesian"),
                   name = NULL) +
  scale_y_continuous(name = "mean % butterfat", expand = c(0, 0)) +
  theme_dviz_hgrid()
```

```{r fig.width = 5}
ggplot(cow_means, aes(x = breed, y = mean, ymin = mean - se, ymax = mean + se)) +
  geom_col(fill = "gray70") +
  geom_linerange() +
  scale_x_discrete(labels = c("Jersey", "Guernsey", "Ayrshire", "Holstein-\nFriesian"),
                   name = NULL) +
  scale_y_continuous(name = "mean % butterfat", expand = c(0, 0)) +
  theme_dviz_hgrid()
```

```{block type='rmdtip', echo=TRUE}
Whenever you visualize uncertainty with error bars, you must specify what quantity and/or confidence level the error bars represent.
```


*Include a coefficient plot from a regression model, as in Cleveland's book?*

```{r}
# relevant materials: 
# Bowman "Graphs for Uncertainty": http://www.rss.org.uk/Images/PDF/events/2018/Bowman-5-Sept-2018.pdf
# R package denstrip: https://cran.r-project.org/package=denstrip

library(ggplot2)
library(rlang)
library(dplyr)
library(tidyr)

stat_conf_band <- function(mapping = NULL, data = NULL,
                           geom = "tile", position = "identity",
                           ...,
                           confidence = 0.95,
                           xlim = NULL,
                           n = 501,
                           na.rm = FALSE,
                           show.legend = FALSE,
                           inherit.aes = TRUE) {
  layer(
    data = data,
    mapping = mapping,
    stat = StatConfBand,
    geom = geom,
    position = position,
    show.legend = show.legend,
    inherit.aes = inherit.aes,
    params = list(
      confidence = confidence,
      n = n,
      na.rm = na.rm,
      xlim = xlim,
      ...
    )
  )
}

fit_normal <- function(mean, moe, confidence = 0.95) {
  # convert to two-tailed value
  confidence <- 1-(1-confidence)/2
  function(x) dnorm(x, mean = mean, sd = moe/qnorm(confidence))
}

StatConfBand <- ggproto("StatConfBand", Stat,
  required_aes = c("mean", "moe"),                        
  default_aes = aes(fill = stat(ndensity)),
                        
  compute_group = function(data, scales, confidence = 0.95, xlim = NULL, n = 501) {
    # Check that confidence band parameters are constant within group
    params <- unique(data[c("mean", "moe")])
    if (nrow(params) > 1) {
      stop("Confidence band parameters can not vary within data groups", call. = FALSE)
    }
    params <- c(as.list(params), list(confidence = confidence))
    
    range <- xlim %||% scales$x$dimension()
    xseq <- seq(range[1], range[2], length.out = n)
    
    if (scales$x$is_discrete()) {
      x_trans <- xseq
    } else {
      # For continuous scales, need to back transform from transformed range
      # to original values
      x_trans <- scales$x$trans$inverse(xseq)
    }
    
    fun <- do.call(fit_normal, params)
    density <- fun(x_trans)
    
    data.frame(
      x = xseq,
      density = density,
      ndensity = density/max(density)
    )
  }
)

df_in <- data.frame(
  group = letters[1:3],
  mean = c(1, 3, 2),
  sd = c(.8, .4, .7)
)

df_data <- mutate(df_in, 
    value = purrr::map2(mean, sd, ~rnorm(250, .x, .y))
  ) %>%
  unnest()

df_out <- group_by(df_data, group) %>%
  summarize(
    mean = mean(value),
    sd = sd(value),
    moe = sd*1.96
  )

ggplot(df_out, aes(x = mean, y = group)) +
  stat_conf_band(aes(mean = mean, moe = sd), height = 0.8, confidence = 0.67) +
  geom_point(data = df_data, aes(x = value), position = position_jitter(width = 0), size = 1) +
  geom_errorbarh(aes(xmin = mean - sd, xmax = mean + sd), height = 0.2, color = "darkred", size = 1) +
  geom_point(size = 3, color = "darkred") +
  scale_fill_gradient(low = "#132B4300", high = "#56B1F7FF") +
  theme_minimal()
```

```{r fig.width = 5.5, fig.asp = 3/4}
sample_posterior_preds <- function(model, samples = 20, n = 100, unconditional = TRUE) {
  predictor <- model$pred.formula[[2]]
  response <- model$terms[[2]]
   
  # make a tibble with a sequence of predictor values
  pred_seq <- tibble(
    !!predictor := seq(
      min(model$model[[predictor]]),
      max(model$model[[predictor]]), 
      length.out = n
    )
  )
  
  # Get the linear prediction matrix
  pred_mat <- predict(
    model,
    newdata  = pred_seq,
    type = "lpmatrix",
    unconditional = unconditional
  )

  # Get the variance-covariance matrix of coefficients
  vcov_mat <- vcov(model, unconditional = unconditional)

  # Draw 20 samples from the posterior and make predictions from them
  coefs <- rmvnorm(samples, mean = coef(model), sigma = vcov_mat)
  preds <- pred_mat %*% t(coefs)
  pred_df <- as_tibble(preds) %>%
    set_names(as.character(1:samples)) %>%
    cbind(pred_seq) %>%
    gather(sample, !!response, -!!predictor)
  
  pred_df
}

# Get the smoothing-uncertainty corrected confidence intervals
confidence_band <- function(model, level = 0.95, n = 100, unconditional = TRUE) {
  predictor <- model$pred.formula[[2]]
  response <- model$terms[[2]]
   
  # make a tibble with a sequence of predictor values
  pred_seq <- tibble(
    !!predictor := seq(
      min(model$model[[predictor]]),
      max(model$model[[predictor]]), 
      length.out = n
    )
  )

  # normal quantile corresponding to confidence level
  std <- stats::qnorm(level / 2 + 0.5)

  # predict confidence band
  predict(
    model,
    newdata = pred_seq,
    se.fit = TRUE,
    unconditional = unconditional
  ) %>%
    as_tibble() %>%
    cbind(pred_seq) %>%
    rename(!!response := fit) %>%
    mutate(
      lo = !!response - std*se.fit,
      hi = !!response + std*se.fit
    )
}


blue_jays_male <- filter(blue_jays, KnownSex == "M")

fit <- gam(Head ~ Mass, data = blue_jays_male, method = "REML")
sample_df <- sample_posterior_preds(fit, 20)
ci_df <- confidence_band(fit)

ggplot(blue_jays_male, aes(Mass, Head)) + 
  geom_ribbon(data = ci_df, aes(ymin = lo, ymax = hi), fill="#80808080", color = NA) +
  geom_point(color = "#0072B2", size = 1.5) +
  geom_line(data = sample_df, aes(group = sample), color = "blue", size = 0.3) +
  geom_line(data = ci_df, color = "red", size = 0.5) +
  scale_x_continuous(
    limits = c(59, 82),
    expand = c(0, 0),
    name = "body mass (g)") +
  scale_y_continuous(
    limits = c(52, 61),
    expand = c(0, 0),
    name = "head length (mm)"
  ) +
  theme_dviz_open()

```

```{r tank-capacity-uncertain, fig.width = 8.5, fig.asp = 3/8, fig.cap='(ref:tank-capacity-uncertain)'}
cars93 <- MASS::Cars93

set.seed(8692282)

fit <- gam(Fuel.tank.capacity ~ s(Price, k = 5, bs = 'cr'), data = cars93)
#fit <- gam(Fuel.tank.capacity ~ s(Price, k = 6, bs = 'gp'), data=cars93)
#fit <- gam(Fuel.tank.capacity ~ s(Price), data = cars93, method = "REML")
sample_df <- sample_posterior_preds(fit, 10, unconditional = FALSE)
ci_df <- confidence_band(fit, unconditional = FALSE)

cars_base <- ggplot(cars93, aes(x = Price, y = Fuel.tank.capacity)) + 
  scale_x_continuous(
    name = "price (USD)",
    breaks = c(20, 40, 60),
    labels = c("$20,000", "$40,000", "$60,000")
  ) +
  scale_y_continuous(name = "fuel-tank capacity\n(US gallons)") +
  theme_minimal_grid(12)

p1 <- cars_base +
  geom_ribbon(data = ci_df, aes(ymin = lo, ymax = hi), fill="grey70", color = NA, alpha = 1/2) +
  geom_point(color = "grey60") +
  geom_line(data = ci_df, color = "#0072B2", size = 1)

p2 <- cars_base +
  geom_ribbon(data = ci_df, aes(ymin = lo, ymax = hi), fill="grey70", color = NA, alpha = 1/2) +
  geom_point(color = "grey60") +
  geom_line(data = sample_df, aes(group = sample), color = "#0072B2", size = 0.3)

plot_grid(
  p1, p2, align = 'hv',
  labels = 'auto'
)

```


## Methods of uncertainty estimates


Table: (\#tab:estimation-frameworks) Comparisons of different approaches to parameter and uncertainty estimation.

------------------------------------------------------------------------------------------
approach       interpretability    computational       complexity of     assumptions on
                of estimates         efficiency        modeling setup       data set
------------ ------------------ ------------------- ------------------- ------------------
Bayesian          high                 low                 high                few

frequentist       moderate              high              moderate            several
parametric  

bootstrap           low                moderate             low                none
------------------------------------------------------------------------------------------


## Hypothetical outcomes plots

Hypothetical outcomes plots: https://medium.com/hci-design-at-uw/hypothetical-outcomes-plots-experiencing-the-uncertain-b9ea60d7c740

## Value-suppressing uncertainty palette


## Contour lines (Staging for overlapping points chapter)

Instead of binning data points into rectangles or hexagons, we can also estimate the point density across the plot area and indicate regions of different point densities with contour lines. This technique works well when the point density changes slowly across both the *x* and the *y* dimensions.

As an example for this approach, we return to the blue jays dataset from Chapter \@ref(visualizing-associations). Figure \@ref(fig:blue-jays-scatter) showed the relationship between head length and body mass for 123 blue jays, and there was some amount of overlap among the points. We can highlight the distribution of points more clearly by making the points smaller and partially transparent and plotting them on top of contour lines that delineate regions of similar point density (Figure \@ref(fig:blue-jays-contour)). We can further enhance the perception of changes in the point density by shading the regions enclosed by the contour lines, using darker colors for regions representing higher point densities (Figure \@ref(fig:blue-jays-contour-filled)).

(ref:blue-jays-contour) Head length versus body mass for 123 blue jays, as in Figure \@ref(fig:blue-jays-scatter). Each dot corresponds to one bird, and the lines indicate regions of similar point density. The point density increases towards the center of the plot, near a body mass of 75g and a head length between 55mm and 57.5mm. Data source: Keith Tarvin, Oberlin College

```{r blue-jays-contour, fig.width = 6, fig.asp = 3/4, fig.cap='(ref:blue-jays-contour)'}

blue_jays_base <- ggplot(blue_jays, aes(Mass, Head)) + 
  scale_x_continuous(
    limits = c(57, 82),
    expand = c(0, 0),
    name = "body mass (g)") +
  scale_y_continuous(
    limits = c(49, 61),
    expand = c(0, 0),
    name = "head length (mm)"
  ) +
  theme_dviz_grid()

blue_jays_base + 
  stat_density_2d(color = "black", size = 0.4, binwidth = 0.004) +
  geom_point(color = "black", size = 1.5, alpha = 1/3)
```

(ref:blue-jays-contour-filled) Head length versus body mass for 123 blue jays. This figure is nearly identical to Figure \@ref(fig:blue-jays-scatter), but now the areas enclosed by the contour lines are shaded with increasingly darker shades of gray. This shading creates a stronger visual impression of increasing point density towards the center of the point cloud. Data source: Keith Tarvin, Oberlin College

```{r blue-jays-contour-filled, fig.width = 6, fig.asp = 3/4, fig.cap='(ref:blue-jays-contour-filled)'}
blue_jays_base + 
  stat_density_2d(aes(fill = ..level..), geom = "polygon", color = "black", size = 0.15, binwidth = 0.004) +
  geom_point(color = "black", size = 1.5, alpha = .4) +
  scale_fill_gradient(low = "grey95", high = "grey70", guide = "none")
```

In Chapter \@ref(visualizing-associations), we also looked at the relationship between head length and body mass separately for male and female birds (Figure \@ref(fig:blue-jays-scatter-sex)). We can do the same with contour lines, by drawing separately colored contour lines for male and female birds (Figure \@ref(fig:blue-jays-contour-by-sex)).

(ref:blue-jays-contour-by-sex) Head length versus body mass for 123 blue jays. As in Figure \@ref(fig:blue-jays-scatter-sex), we can also indicate the birds' sex by color when drawing contour lines. This figure highlights how the point distribution is different for male and female birds. In particular, male birds are more densely clustered in one region of the plot area whereas female birds are more spread out. Data source: Keith Tarvin, Oberlin College

```{r blue-jays-contour-by-sex, fig.width = 6, fig.asp = 3/4, fig.cap='(ref:blue-jays-contour-by-sex)'}
blue_jays_base + 
  aes(color = KnownSex) +
  stat_density_2d(size = 0.4, binwidth = 0.006) +
  geom_point(size = 1.5, alpha = 0.7) +
  scale_color_manual(
    values = c(F = "#D55E00", M = "#0072B2"),
    breaks = c("F", "M"),
    labels = c("female birds   ", "male birds"),
    name = NULL,
    guide = guide_legend(
      direction = "horizontal",
      override.aes = list(size = 2, linetype = 0)
    )
  ) +
  theme_dviz_grid() +
  theme(
    legend.position = c(1, 0),
    legend.justification = c(1, 0),
    #legend.position = "top",
    #legend.justification = "right",
    #legend.box.spacing = unit(3.5, "pt"), # distance between legend and plot
    legend.text = element_text(vjust = 0.6),
    legend.spacing.x = unit(2, "pt"),
    legend.background = element_rect(fill = "white", color = NA),
    #legend.key.width = unit(10, "pt")
    axis.ticks.length = unit(0, "pt"),
    axis.ticks = element_blank()
  )
```

Drawing multiple sets of contour lines in different colors can be a powerful strategy for showing the distributions of several point clouds at once. However, this technique needs to be employed with care. It only works when the number of groups with distinct colors is small (two to three) and the groups are clearly separated. Otherwise, we may end up with a hairball of differently colored lines all crisscrossing each other and not showing any particular pattern at all.

To illustrate this potential problem, I will employ the diamonds dataset, which contains information for 53,940 diamonds, including their price, weight (carat), and cut. Figure \@ref(fig:diamonds-points) shows this dataset as a scatter plot. We see clear problems with overplotting. There are so many different-colored points on top of one another that it is impossible to discern anything beyond the overall broad outline of where diamonds fall on the price--carat spectrum.

(ref:diamonds-points) Price of diamonds versus their carat value, for 53,940 individual diamonds. Each diamond's cut is indicated by color. The plot is labeled as "bad" because the extensive overplotting makes it impossible to discern any patterns among the different diamond cuts. Data source: Hadley Wickham, ggplot2

```{r diamonds-points, fig.asp = 3/4, fig.cap = '(ref:diamonds-points)'}
p <- ggplot(diamonds, aes(carat, price, color = cut)) + 
  geom_point(size = .2, alpha = 1/5) +
  scale_x_continuous(
    limits = c(-1, 5.1)
  ) +
  scale_y_log10(
    name = "price (USD)",
    breaks = c(300, 1000, 3000, 10000),
    labels = c("$300", "$1,000", "$3,000", "$10,000")
  ) +
  scale_color_discrete_sequential(
    palette = "Inferno",
    nmax = 6,
    order = 1:5,
    breaks = c("Ideal", "Premium", "Very Good", "Good", "Fair"),
    labels = c("ideal", "premium", "very good", "good", "fair"),
    guide = guide_legend(
      override.aes = list(size = 2, alpha = 1)
    )
  ) +
  coord_cartesian(xlim = c(-.1, 3.2), ylim = c(240, 25000), expand = FALSE) + 
  theme_dviz_grid() +
  panel_border() +
  theme(
    plot.margin = margin(18, 7, 1, 0),
    legend.key.width = unit(6, "pt"),
    legend.spacing.y = unit(3, "pt"),
    legend.title = element_text(hjust = 0, margin = margin(0, 0, 0, 0)),
    legend.position = c(.97, .3),
    legend.justification = c(1, 0.5),
    legend.box.margin = margin(7, 7, 7, 7),
    legend.box.background = element_rect(fill = "white", color = NA),
    axis.ticks.length = unit(0, "pt")
  )

stamp_bad(p)
```

We could try to draw colored contour lines for the different qualities of cut, as in Figure \@ref(fig:blue-jays-contour-by-sex). However, in the diamonds dataset, we have five distinct colors and the groups strongly overlap. Therefore, the contour plot (Figure \@ref(fig:diamonds-contour-colors)) is not much better than the original scatter plot (Figure \@ref(fig:diamonds-points)).

(ref:diamonds-contour-colors) Price of diamonds versus their carat value. As Figure \@ref(fig:diamonds-points), but now individual points have been replaced by contour lines. The resulting plot is still labeled "bad", because the contour lines all lie on top of each other. Neither the point distribution for individual cuts nor the overall point distribution can be discerned. Data source: Hadley Wickham, ggplot2


```{r diamonds-contour-colors, fig.asp = 3/4}
p <- ggplot(diamonds, aes(carat, price, color = cut)) + 
  geom_density2d(size = .35, binwidth = 0.8) +
  scale_x_continuous(
    limits = c(-1, 5.1)
  ) +
  scale_y_log10(
    name = "price (USD)",
    breaks = c(300, 1000, 3000, 10000),
    labels = c("$300", "$1,000", "$3,000", "$10,000")
  ) +
  scale_color_discrete_sequential(
    palette = "Inferno",
    nmax = 6,
    order = 1:5,
    breaks = c("Ideal", "Premium", "Very Good", "Good", "Fair"),
    labels = c("ideal", "premium", "very good", "good", "fair"),
    guide = guide_legend(
      override.aes = list(size = 0.5)
    )
  ) +
  coord_cartesian(xlim = c(-.1, 2.3), ylim = c(240, 25000), expand = FALSE) + 
  theme_dviz_grid() +
  panel_border() +
  theme(
    plot.margin = margin(18, 7, 1, 0),
    legend.spacing.y = unit(3, "pt"),
    legend.title = element_text(hjust = 0, margin = margin(0, 0, 0, 0)),
    legend.position = c(.97, .3),
    legend.justification = c(1, 0.5),
    legend.box.margin = margin(7, 7, 7, 7),
    legend.box.background = element_rect(fill = "white", color = NA),
    axis.ticks.length = unit(0, "pt")
  )

stamp_bad(p)
```

What helps here is to draw the contour lines for each cut quality in its own plot panel (Figure \@ref(fig:diamonds-contour-facets)). The purpose of drawing them all in one panel might be to enable visual comparison between the groups, but Figure \@ref(fig:diamonds-contour-colors) is so busy that a comparison isn't possible.  Instead, in Figure \@ref(fig:diamonds-contour-facets), the background grid enables us to make  comparisons across cut qualities, by paying attention to where exactly the contour lines fall relative to the grid lines.

(ref:diamonds-contour-facets) Price of diamonds versus their carat value. Here, we have taken the density contours from Figure \@ref(fig:diamonds-contour-colors) and drawn them separately for each cut. We can now see that better cuts (very good, premium, ideal) tend to have lower carat values than the poorer cuts (fair, good) but command a higher price per carat. Data source: Hadley Wickham, ggplot2


```{r diamonds-contour-facets, fig.width = 8.5, fig.asp = 3/4, fig.cap = "(ref:diamonds-contour-facets)"}
ggplot(diamonds, aes(carat, price)) + 
  stat_density_2d(aes(fill = ..level..), geom = "polygon", color = darken("#0072B2", .2), size = .3, binwidth = 0.8) +
  #geom_density2d(color = darken("#0072B2", .2), size = .3, binwidth = 0.8) +
  scale_fill_gradient(low = desaturate(lighten("#0072B2", .9), .6), high = desaturate(lighten("#0072B2", .6), .6), guide = "none") +
  scale_x_continuous(
    limits = c(-1, 5.1)
  ) +
  scale_y_log10(
    name = "price (USD)",
    breaks = c(300, 1000, 3000, 10000),
    labels = c("$300", "$1,000", "$3,000", "$10,000")
  ) +
  coord_cartesian(xlim = c(-.1, 2.3), ylim = c(200, 25000), expand = FALSE) + 
  facet_wrap(~cut, scales = "free_x", labeller = labeller(cut = tolower)) +
  theme_dviz_grid() +
  panel_border() +
  theme(
    legend.title = element_text(hjust = 0.5),
    legend.position = c(.95, .05),
    legend.justification = c(1, 0),
    axis.ticks.length = unit(0, "pt")
  )
```

We can make out two main trends. First, the better cuts (very good, premium, ideal) tend to have lower carat values than the poorer cuts (fair, good). Recall that carat is a measure of diamond weight (1 carat = 0.2 gram). Better cuts tend to result (on average) in lighter diamonds because more material needs to be removed to create them. Second, at the same carat value, better cuts tend to command higher prices. To see this pattern, look for example at the price distribution for 0.5 carat. The distribution is shifted upwards for better cuts, and in particular it is substantially higher for diamonds with ideal cut than for diamonds with fair or good cut.
